{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Exercise Sheet 1, Task 3\n",
    "\n",
    "This is one possible solution for how to implement the classifier. I added another example to show how using multiple outputs has an advantage over a single binary output neuron. This new sample also adds the word \"and\" to the vocabulary. As a result, our Bag of Words vectors and the weight matrices will also change slightly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-28T17:58:04.731335Z",
     "start_time": "2023-04-28T17:58:04.730920Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and', 'cats', 'dogs', 'i', 'like', 'mostly', 'really']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Our document corpus\n",
    "sample_strings = [\"I really like cats\", \"I mostly like dogs\",  \"I really like dogs\", \"I like dogs and cats\"]\n",
    "\n",
    "def tokenize(sample):\n",
    "    \"\"\"\n",
    "    A tokenizer to split the strings into tokens\n",
    "    For simplicity we just split on whitespace.\n",
    "    :param sample: A string to be tokenized\n",
    "    :return: a list of tokens\n",
    "    \"\"\"\n",
    "    tokens = []\n",
    "    return sample.lower().split(\" \")\n",
    "\n",
    "def build_vocabulary(samples):\n",
    "    \"\"\"\n",
    "    Builds a vocabulary from a list of strings\n",
    "    :param samples: A list of strings\n",
    "    :return: A list of unique tokens\n",
    "    \"\"\"\n",
    "    vocabulary = []\n",
    "    for sample in samples:\n",
    "        tokens = tokenize(sample)\n",
    "        for token in tokens:\n",
    "            if token not in vocabulary:\n",
    "                vocabulary.append(token)\n",
    "    return vocabulary\n",
    "\n",
    "vocabulary = build_vocabulary(sample_strings)\n",
    "vocabulary.sort()\n",
    "print(vocabulary)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Now let us build our Bag of Words representations for our samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-28T17:58:04.731487Z",
     "start_time": "2023-04-28T17:58:04.731008Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and', 'cats', 'dogs', 'i', 'like', 'mostly', 'really']\n",
      "I really like cats:[[0. 1. 0. 1. 1. 0. 1.]]\n",
      "I mostly like dogs:[[0. 0. 1. 1. 1. 1. 0.]]\n",
      "I really like dogs:[[0. 0. 1. 1. 1. 0. 1.]]\n",
      "I like dogs and cats:[[1. 1. 1. 1. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "def build_bag_of_words(sample, vocabulary):\n",
    "    \"\"\"\n",
    "    Builds a bag of words representation for a given sample\n",
    "    :param sample: A string\n",
    "    :param vocabulary: A list of unique tokens\n",
    "    :return: A vector of shape (len(vocabulary),1)\n",
    "    \"\"\"\n",
    "    tokens = tokenize(sample)\n",
    "    bag_of_words = np.zeros((len(vocabulary),1))\n",
    "    for token in tokens:\n",
    "        for i, word in enumerate(vocabulary):\n",
    "            if word == token:\n",
    "                bag_of_words[i] += 1\n",
    "    return bag_of_words\n",
    "\n",
    "bow_samples = []\n",
    "print(vocabulary)\n",
    "for sample in sample_strings:\n",
    "    bow_samples.append(build_bag_of_words(sample, vocabulary))\n",
    "    #After adding our new BoW-sample we print the latest one.\n",
    "    #We also use the .T attribute to transpose the vector to make it more readable.\n",
    "    #We could also use the transpose() function for this.\n",
    "    print(\"{}:{}\".format(sample,bow_samples[-1].T))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "We now construct our weight matrices. We will use a weight matrix of shape (2,7) since we have two classes and seven words in our vocabulary. This way we can calculate the output of our classifier by simply multiplying the weight matrix with the BoW vector.\n",
    "If you pay attention to the shape of our matrices, you will notice that they are transposed compared to the ones in the sample solution I uploaded. This way, we will use the same order of multiplication as in the lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-28T17:58:04.731550Z",
     "start_time": "2023-04-28T17:58:04.731050Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#First, let's build our ideal classifier. This one looks at the words \"cats\" and \"dogs\"\n",
    "good_weights = np.matrix([[0,1,0,0,0,0,0],[0,0,1,0,0,0,0]])\n",
    "#But this one looks at the words \"mostly\" and \"really\". It works for the first two samples but not for the other ones.\n",
    "bad_weights = np.matrix([[0,0,0,0,0,0,1],[0,0,0,0,0,1,0]])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Now let's build our simple classifier. Note, that we use the formula from the lecture to calculate the output of the classifier: f(x) = Wx\n",
    "\n",
    "For simplicity we do not use a bias term here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-28T17:58:04.731593Z",
     "start_time": "2023-04-28T17:58:04.731081Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class classifier:\n",
    "    def __init__(self, weights):\n",
    "        \"\"\"\n",
    "        :param weights: a numpy matrix of shape (2,7) containing the weights for the classifier\n",
    "        \"\"\"\n",
    "        self.weights = weights\n",
    "\n",
    "    def classify(self, bow_input):\n",
    "        \"\"\"\n",
    "        Returns the output of applying the weights to a given input.\n",
    "        The output is vector of length 2, and the first entry is the classifier output for the topic \"cats\",\n",
    "        while the second entry is the classifier output for the topic \"dogs\"\n",
    "        :param bow_input: a numpy array of length 7 containing the bag of words representation of the input sentence\n",
    "        :return: a numpy matrix of shape (2,1) containing the classifier output\n",
    "        \"\"\"\n",
    "        #'@' performs matrix multiplication in numpy\n",
    "        return self.weights@bow_input"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Let's also build a small utility function to describe the output of our classifier in a human-readable way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-28T17:58:04.731631Z",
     "start_time": "2023-04-28T17:58:04.731136Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def labels_to_string(labels):\n",
    "    \"\"\"\n",
    "    build a string from the classifier output to make the vector interpretable\n",
    "    :param labels: a numpy matrix of shape (2,1) containing the classifier output\n",
    "    :return: a string describing the classifier output\n",
    "    \"\"\"\n",
    "    topics = []\n",
    "    if labels[0] > 0:\n",
    "        topics.append(\"cats\")\n",
    "    if labels[1] > 0:\n",
    "        topics.append(\"dogs\")\n",
    "    return \"Sentence is about {}.\".format(\" and \".join(topics)) if topics else \"Sentence is about neither cats nor dogs.\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "All we have to do now is to create instances of our classifier and use it to classify our samples. The first classifier should provide us with the correct classifications, but the second ond should make some mistakes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-28T17:58:04.771166Z",
     "start_time": "2023-04-28T17:58:04.731166Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample: I really like cats\n",
      "Good classifier output: [[1. 0.]]. Sentence is about cats.\n",
      "Bad classifier output: [[1. 0.]]. Sentence is about cats.\n",
      "\n",
      "Sample: I mostly like dogs\n",
      "Good classifier output: [[0. 1.]]. Sentence is about dogs.\n",
      "Bad classifier output: [[0. 1.]]. Sentence is about dogs.\n",
      "\n",
      "Sample: I really like dogs\n",
      "Good classifier output: [[0. 1.]]. Sentence is about dogs.\n",
      "Bad classifier output: [[1. 0.]]. Sentence is about cats.\n",
      "\n",
      "Sample: I like dogs and cats\n",
      "Good classifier output: [[1. 1.]]. Sentence is about cats and dogs.\n",
      "Bad classifier output: [[0. 0.]]. Sentence is about neither cats nor dogs.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "good_classifier = classifier(good_weights)\n",
    "bad_classifier = classifier(bad_weights)\n",
    "for idx,sample in enumerate(bow_samples):\n",
    "    good_output = good_classifier.classify(sample)\n",
    "    bad_output = bad_classifier.classify(sample)\n",
    "    print(\"Sample: {}\".format(sample_strings[idx]))\n",
    "    print(\"Good classifier output: {}. {}\".format(good_output.reshape(2,), labels_to_string(good_output)))\n",
    "    print(\"Bad classifier output: {}. {}\\n\".format(bad_output.reshape(2,), labels_to_string(bad_output)))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
